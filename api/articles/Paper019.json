{"title":"百度_ICML2015_Deep Speech 2：End-to-End Speech Recognition in English and Mandarin","slug":"Paper019","date":"2021-01-18T14:39:52.000Z","updated":"2021-03-20T08:14:55.000Z","comments":true,"path":"api/articles/Paper019.json","excerpt":null,"covers":null,"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><p><strong>摘要</strong><br>我们证明了一种端到端的深度学习方法可以用于识别英语或普通话——两种截然不同的语言。由于该方法用神经网络取代了整个手工设计的组件管道，端到端学习使我们能够处理各种各样的语音，包括嘈杂环境、口音和不同的语言。我们方法的关键是我们的HPC（高性能计算）技术的应用，以致于比我们以前的系统提速7倍。由于这种效率，以前需要几周时间的实验，而现在只需几天就能完成。这使我们能够更快地迭代以验证更优秀的架构和算法。因此，在一些情况下，当以标准数据集为基准时，我们的系统与人类工作者的转录结果一样好。最后，通过在数据中心使用GPUs进行批量调度，我们证明了我们的系统可以以低廉的成本在线部署，并在大规模服务用户时提供低延迟。</p>\n<p><strong>参考</strong><br>[1] <em>Amodei D, Ananthanarayanan S, Anubhai R, et al. Deep speech 2: End-to-end speech recognition in english and mandarin[C]//International conference on machine learning. 2016: 173-182.</em><a href=\"https://arxiv.org/abs/1512.02595\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>DeepSpeech-PaddlePaddle</em><a href=\"https://github.com/PaddlePaddle/DeepSpeech\">[GitHub]</a><br>[2] <em>DeepSpeech-TensorFlow</em><a href=\"https://github.com/mozilla/DeepSpeech\">[GitHub]</a><br>[3] <em>DeepSpeech-PyTorch</em><a href=\"https://github.com/SeanNaren/deepspeech.pytorch\">[GitHub]</a><br>[4] <em>DeepSpeech-Neon</em><a href=\"https://github.com/NervanaSystems/deepspeech\">[GitHub]</a><br>[5] <em>DeepSpeech-MXNet</em><a href=\"https://github.com/samsungsds-rnd/deepspeech.mxnet\">[GitHub]</a><br>[6] <em>DeepSpeech-Keras</em><a href=\"https://github.com/robmsmt/KerasDeepSpeech\">[GitHub]</a></p>\n","more":"<p><strong>摘要</strong><br>我们证明了一种端到端的深度学习方法可以用于识别英语或普通话——两种截然不同的语言。由于该方法用神经网络取代了整个手工设计的组件管道，端到端学习使我们能够处理各种各样的语音，包括嘈杂环境、口音和不同的语言。我们方法的关键是我们的HPC（高性能计算）技术的应用，以致于比我们以前的系统提速7倍。由于这种效率，以前需要几周时间的实验，而现在只需几天就能完成。这使我们能够更快地迭代以验证更优秀的架构和算法。因此，在一些情况下，当以标准数据集为基准时，我们的系统与人类工作者的转录结果一样好。最后，通过在数据中心使用GPUs进行批量调度，我们证明了我们的系统可以以低廉的成本在线部署，并在大规模服务用户时提供低延迟。</p>\n<p><strong>参考</strong><br>[1] <em>Amodei D, Ananthanarayanan S, Anubhai R, et al. Deep speech 2: End-to-end speech recognition in english and mandarin[C]//International conference on machine learning. 2016: 173-182.</em><a href=\"https://arxiv.org/abs/1512.02595\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>DeepSpeech-PaddlePaddle</em><a href=\"https://github.com/PaddlePaddle/DeepSpeech\">[GitHub]</a><br>[2] <em>DeepSpeech-TensorFlow</em><a href=\"https://github.com/mozilla/DeepSpeech\">[GitHub]</a><br>[3] <em>DeepSpeech-PyTorch</em><a href=\"https://github.com/SeanNaren/deepspeech.pytorch\">[GitHub]</a><br>[4] <em>DeepSpeech-Neon</em><a href=\"https://github.com/NervanaSystems/deepspeech\">[GitHub]</a><br>[5] <em>DeepSpeech-MXNet</em><a href=\"https://github.com/samsungsds-rnd/deepspeech.mxnet\">[GitHub]</a><br>[6] <em>DeepSpeech-Keras</em><a href=\"https://github.com/robmsmt/KerasDeepSpeech\">[GitHub]</a></p>\n","categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语言模型","path":"api/tags/语言模型.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"CNN","path":"api/tags/CNN.json"},{"name":"GRU","path":"api/tags/GRU.json"},{"name":"LSTM","path":"api/tags/LSTM.json"},{"name":"KenLM","path":"api/tags/KenLM.json"}]}