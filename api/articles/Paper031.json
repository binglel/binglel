{"title":"CMU_ICASSP2016_Listen, Attend and Spell","slug":"Paper031","date":"2021-02-19T08:44:24.000Z","updated":"2021-02-19T09:31:22.000Z","comments":true,"path":"api/articles/Paper031.json","excerpt":null,"covers":null,"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><p><strong>摘要</strong><br>我们介绍了Listen, Attend and Spell（LAS），这是一种学习将语音转录成字符的神经网络。与传统的DNN-HMM模型不同，该模型联合学习语音识别器的所有组件。该系统有两个组件：监听器和拼写器。监听器是接受滤波器组频谱作为输入的金字塔循环网络编码器。拼写器是基于注意力的循环网络解码器，以字符作为输出。该网络输出字符序列，而不在字符之间做出任何独立假设。这是LAS相对于以往端到端CTC模型的关键改进。在谷歌语音搜索任务的一个子集上，LAS在没有词典或语言模型的情况下实现了14.1%的词错误率（WER），在前32个波束上进行语言模型重新评分的情况下实现了10.3%的词错误率。相比之下，最先进的CLDNN-HMM模型达到了8.0%的WER。</p>\n<p><strong>参考</strong><br>[1] <em>Chan W, Jaitly N, Le Q V, et al. Listen, attend and spell[J]. arXiv preprint arXiv:1508.01211, 2015.</em><a href=\"https://arxiv.org/abs/1508.01211\">[pdf]</a></p>\n","more":"<p><strong>摘要</strong><br>我们介绍了Listen, Attend and Spell（LAS），这是一种学习将语音转录成字符的神经网络。与传统的DNN-HMM模型不同，该模型联合学习语音识别器的所有组件。该系统有两个组件：监听器和拼写器。监听器是接受滤波器组频谱作为输入的金字塔循环网络编码器。拼写器是基于注意力的循环网络解码器，以字符作为输出。该网络输出字符序列，而不在字符之间做出任何独立假设。这是LAS相对于以往端到端CTC模型的关键改进。在谷歌语音搜索任务的一个子集上，LAS在没有词典或语言模型的情况下实现了14.1%的词错误率（WER），在前32个波束上进行语言模型重新评分的情况下实现了10.3%的词错误率。相比之下，最先进的CLDNN-HMM模型达到了8.0%的WER。</p>\n<p><strong>参考</strong><br>[1] <em>Chan W, Jaitly N, Le Q V, et al. Listen, attend and spell[J]. arXiv preprint arXiv:1508.01211, 2015.</em><a href=\"https://arxiv.org/abs/1508.01211\">[pdf]</a></p>\n","categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"BLSTM","path":"api/tags/BLSTM.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"},{"name":"LAS","path":"api/tags/LAS.json"}]}