{"title":"出门问问_ICASSP2019_Knowledge Distillation for Recurrent Neural Network Language Modeling with Trust Regularization","slug":"Paper025","date":"2021-01-24T03:24:38.000Z","updated":"2021-01-24T03:35:30.000Z","comments":true,"path":"api/articles/Paper025.json","excerpt":null,"covers":null,"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><p><strong>摘要</strong><br>循环神经网络（RNNs）因其优于传统的基于N元语法的模型而在语言建模中占据主导地位。在许多应用中，通常使用大型循环神经网络语言模型（RNNLM）或几个RNNLM的集成。这些模型占用的内存很大且需要大量的计算。在这篇文章中，我们研究了应用知识蒸馏来降低RNNLMs模型大小的效果。此外，我们还提出了一种信任正则化方法来改进RNNLM的知识提炼训练。利用信任正则化的知识精馏，我们将参数大小减少到以前发表的最佳模型的三分之一，同时保持了对Penn Treebank数据的最先进困惑度结果。在语音识别N-bestrescoring任务中，我们将RNNLM模型的规模减少到基线系统的18.5%，而在华尔街日报数据集上的错词率（WER）性能没有下降。</p>\n<p><strong>参考</strong><br>[1] <em>Shi Y, Hwang M Y, Lei X, et al. Knowledge distillation for recurrent neural network language modeling with trust regularization[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 7230-7234.</em><a href=\"https://arxiv.org/abs/1904.04163\">[pdf]</a></p>\n","more":"<p><strong>摘要</strong><br>循环神经网络（RNNs）因其优于传统的基于N元语法的模型而在语言建模中占据主导地位。在许多应用中，通常使用大型循环神经网络语言模型（RNNLM）或几个RNNLM的集成。这些模型占用的内存很大且需要大量的计算。在这篇文章中，我们研究了应用知识蒸馏来降低RNNLMs模型大小的效果。此外，我们还提出了一种信任正则化方法来改进RNNLM的知识提炼训练。利用信任正则化的知识精馏，我们将参数大小减少到以前发表的最佳模型的三分之一，同时保持了对Penn Treebank数据的最先进困惑度结果。在语音识别N-bestrescoring任务中，我们将RNNLM模型的规模减少到基线系统的18.5%，而在华尔街日报数据集上的错词率（WER）性能没有下降。</p>\n<p><strong>参考</strong><br>[1] <em>Shi Y, Hwang M Y, Lei X, et al. Knowledge distillation for recurrent neural network language modeling with trust regularization[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 7230-7234.</em><a href=\"https://arxiv.org/abs/1904.04163\">[pdf]</a></p>\n","categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语言模型","path":"api/tags/语言模型.json"},{"name":"RNNLM","path":"api/tags/RNNLM.json"}]}