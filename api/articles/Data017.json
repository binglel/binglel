{"title":"约翰斯·霍普金斯大学_Datasets_LibriSpeech","slug":"Data017","date":"2021-03-14T04:45:16.000Z","updated":"2021-03-31T06:28:03.000Z","comments":true,"path":"api/articles/Data017.json","excerpt":null,"covers":null,"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><blockquote>\n<p><a href=\"https://www.clsp.jhu.edu/\">The Center for Language and Speech Processing (CLSP@JHU)</a></p>\n</blockquote>\n<ul>\n<li>下载地址<ul>\n<li><a href=\"http://www.openslr.org/12/\">0penSLR</a> / <a href=\"https://openslr.magicdatatech.com/12/\">OpenSLR-China</a><br>Large-scale (1000 hours) corpus of read English speech</li>\n<li><a href=\"http://www.openslr.org/31/\">0penSLR</a> / <a href=\"https://openslr.magicdatatech.com/31/\">OpenSLR-China</a><br>Subset of LibriSpeech corpus for purpose of regression testing</li>\n</ul>\n</li>\n</ul>\n<p>Librispeech是由kaldi开发者整理并发布的免费英语朗读数据，其数据总量是<code>960小时</code>，内容来自有声电子书项目LibriVox。</p>\n<p><strong>数据内容</strong><br>train-clean-100：251个说话人<br>train-clean-360：921个说话人<br>train-clean-500：1166个说话人<br>……</p>\n<p><strong>参考</strong><br>[1] <em>Panayotov V, Chen G, Povey D, et al. Librispeech: an asr corpus based on public domain audio books[C]//2015 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2015: 5206-5210.</em><a href=\"http://www.danielpovey.com/files/2015_icassp_librispeech.pdf\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>kaldi</em><a href=\"https://github.com/kaldi-asr/kaldi\">[GitHub]</a><br>[2] <em>wenet</em><a href=\"https://github.com/mobvoi/wenet\">[GitHub]</a></p>\n","more":"<blockquote>\n<p><a href=\"https://www.clsp.jhu.edu/\">The Center for Language and Speech Processing (CLSP@JHU)</a></p>\n</blockquote>\n<ul>\n<li>下载地址<ul>\n<li><a href=\"http://www.openslr.org/12/\">0penSLR</a> / <a href=\"https://openslr.magicdatatech.com/12/\">OpenSLR-China</a><br>Large-scale (1000 hours) corpus of read English speech</li>\n<li><a href=\"http://www.openslr.org/31/\">0penSLR</a> / <a href=\"https://openslr.magicdatatech.com/31/\">OpenSLR-China</a><br>Subset of LibriSpeech corpus for purpose of regression testing</li>\n</ul>\n</li>\n</ul>\n<p>Librispeech是由kaldi开发者整理并发布的免费英语朗读数据，其数据总量是<code>960小时</code>，内容来自有声电子书项目LibriVox。</p>\n<p><strong>数据内容</strong><br>train-clean-100：251个说话人<br>train-clean-360：921个说话人<br>train-clean-500：1166个说话人<br>……</p>\n<p><strong>参考</strong><br>[1] <em>Panayotov V, Chen G, Povey D, et al. Librispeech: an asr corpus based on public domain audio books[C]//2015 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2015: 5206-5210.</em><a href=\"http://www.danielpovey.com/files/2015_icassp_librispeech.pdf\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>kaldi</em><a href=\"https://github.com/kaldi-asr/kaldi\">[GitHub]</a><br>[2] <em>wenet</em><a href=\"https://github.com/mobvoi/wenet\">[GitHub]</a></p>\n","categories":[{"name":"Data","path":"api/categories/Data.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"Kaldi","path":"api/tags/Kaldi.json"},{"name":"语音数据集","path":"api/tags/语音数据集.json"},{"name":"英文语音数据集","path":"api/tags/英文语音数据集.json"}]}