{"title":"台湾大学_Interspeech2019_One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization","slug":"Paper010","date":"2020-12-28T14:56:11.000Z","updated":"2021-05-27T03:25:24.000Z","comments":true,"path":"api/articles/Paper010.json","excerpt":null,"covers":null,"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><p><strong>摘要</strong><br>近年来，无需平行数据的语音转换（VC）已成功地应用于多目标场景，即训练单个模型将输入语音转换为多个不同的说话人。然而，这种模型存在着只能将语音转换为训练数据中说话人的局限性，这就限制了语言转换的适用场景。本文提出了一种新型的One-shot语音转换方法，该方法只需源说话人和目标说话人的一个示例话语就可以实现语音转换，而且在训练过程中甚至不需要出现源说话人和目标说话人。这是通过实例规范化（IN）实现说话人和内容表征分离。客观和主观评价表明，该模型能够生成与目标说话人相似的语音。除了性能测量之外，我们还证明了该模型能够在没有任何监督的情况下学习有意义的说话人表征。</p>\n<p><strong>参考</strong><br>[1] <em>Chou J, Yeh C, Lee H. One-shot voice conversion by separating speaker and content representations with instance normalization[J]. arXiv preprint arXiv:1904.05742, 2019.</em><a href=\"https://arxiv.org/abs/1904.05742\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>adaptive_voice_conversion</em><a href=\"https://github.com/jjery2243542/adaptive_voice_conversion\">[GitHub]</a></p>\n","more":"<p><strong>摘要</strong><br>近年来，无需平行数据的语音转换（VC）已成功地应用于多目标场景，即训练单个模型将输入语音转换为多个不同的说话人。然而，这种模型存在着只能将语音转换为训练数据中说话人的局限性，这就限制了语言转换的适用场景。本文提出了一种新型的One-shot语音转换方法，该方法只需源说话人和目标说话人的一个示例话语就可以实现语音转换，而且在训练过程中甚至不需要出现源说话人和目标说话人。这是通过实例规范化（IN）实现说话人和内容表征分离。客观和主观评价表明，该模型能够生成与目标说话人相似的语音。除了性能测量之外，我们还证明了该模型能够在没有任何监督的情况下学习有意义的说话人表征。</p>\n<p><strong>参考</strong><br>[1] <em>Chou J, Yeh C, Lee H. One-shot voice conversion by separating speaker and content representations with instance normalization[J]. arXiv preprint arXiv:1904.05742, 2019.</em><a href=\"https://arxiv.org/abs/1904.05742\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>adaptive_voice_conversion</em><a href=\"https://github.com/jjery2243542/adaptive_voice_conversion\">[GitHub]</a></p>\n","categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"语音转换","path":"api/tags/语音转换.json"},{"name":"合成器","path":"api/tags/合成器.json"},{"name":"Tacotron","path":"api/tags/Tacotron.json"},{"name":"声码器","path":"api/tags/声码器.json"},{"name":"Griffin-Lim","path":"api/tags/Griffin-Lim.json"},{"name":"声纹编码器","path":"api/tags/声纹编码器.json"},{"name":"内容编码器","path":"api/tags/内容编码器.json"},{"name":"Instance Normalization","path":"api/tags/Instance Normalization.json"}]}