{"title":"谷歌_NeurIPS2018_Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis","slug":"Paper005","date":"2020-12-26T03:45:48.000Z","updated":"2020-12-28T13:52:38.000Z","comments":true,"path":"api/articles/Paper005.json","excerpt":null,"covers":null,"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><p><strong>摘要</strong><br>我们描述了一种基于神经网络的文本到语音合成系统，该系统能够生成许多不同说话人音色的声音，包括在模型训练中未出现说话人的声音。我们的系统由三个独立训练的模块组成：（1）说话人编码器网络，使用来自成千上万说话人且没有抄本的独立带噪语音数据集对说话人识别任务进行训练，以从目标说话人的仅几秒参考语音中生成固定维度的嵌入矢量；（2）一个基于Tacotron2的序列到序列合成网络，该网络根据说话者的嵌入情况从文本生成梅尔频谱图；（3）一种基于WaveNet的自回归声码器，可将mel频谱图转换为一系列时域波形​​样本。我们证明了所提出的模型能够通过独立训练的说话人编码器把学到的说话人可变知识迁移到新任务（多说话人语音合成）中，并且能够合成在训练过程中未出现说话人的自然声音。我们量化了在大量多样的说话人数据集上训练说话人编码器的重要性，以获得最佳的泛化性能。最后表明，随机采样的说话人嵌入方法可用于合成不同于模型训练所使用说话人的新颖说话人音色的语音，这说明该模型已学到了高质量的说话人表征。</p>\n<p><strong>参考</strong><br>[1] <em>Jia Y, Zhang Y, Weiss R, et al. Transfer learning from speaker verification to multispeaker text-to-speech synthesis[C]//Advances in neural information processing systems. 2018: 4480-4490.</em><a href=\"https://arxiv.org/abs/1806.04558\">[pdf]</a></p>\n","more":"<p><strong>摘要</strong><br>我们描述了一种基于神经网络的文本到语音合成系统，该系统能够生成许多不同说话人音色的声音，包括在模型训练中未出现说话人的声音。我们的系统由三个独立训练的模块组成：（1）说话人编码器网络，使用来自成千上万说话人且没有抄本的独立带噪语音数据集对说话人识别任务进行训练，以从目标说话人的仅几秒参考语音中生成固定维度的嵌入矢量；（2）一个基于Tacotron2的序列到序列合成网络，该网络根据说话者的嵌入情况从文本生成梅尔频谱图；（3）一种基于WaveNet的自回归声码器，可将mel频谱图转换为一系列时域波形​​样本。我们证明了所提出的模型能够通过独立训练的说话人编码器把学到的说话人可变知识迁移到新任务（多说话人语音合成）中，并且能够合成在训练过程中未出现说话人的自然声音。我们量化了在大量多样的说话人数据集上训练说话人编码器的重要性，以获得最佳的泛化性能。最后表明，随机采样的说话人嵌入方法可用于合成不同于模型训练所使用说话人的新颖说话人音色的语音，这说明该模型已学到了高质量的说话人表征。</p>\n<p><strong>参考</strong><br>[1] <em>Jia Y, Zhang Y, Weiss R, et al. Transfer learning from speaker verification to multispeaker text-to-speech synthesis[C]//Advances in neural information processing systems. 2018: 4480-4490.</em><a href=\"https://arxiv.org/abs/1806.04558\">[pdf]</a></p>\n","categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"语音转换","path":"api/tags/语音转换.json"},{"name":"说话人认证","path":"api/tags/说话人认证.json"},{"name":"说话人风格迁移","path":"api/tags/说话人风格迁移.json"},{"name":"合成器","path":"api/tags/合成器.json"},{"name":"声码器","path":"api/tags/声码器.json"},{"name":"Tacotron2","path":"api/tags/Tacotron2.json"},{"name":"WaveNet","path":"api/tags/WaveNet.json"},{"name":"声纹编码器","path":"api/tags/声纹编码器.json"}]}