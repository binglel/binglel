{"title":"康奈尔大学_CVPR2017_Densely Connected Convolutional Networks","slug":"Paper041","date":"2021-05-07T06:59:59.000Z","updated":"2021-05-07T07:38:47.000Z","comments":true,"path":"api/articles/Paper041.json","excerpt":null,"covers":null,"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><p><strong>摘要</strong><br>最近的研究表明，如果卷积网络在靠近输入的层和靠近输出的层之间包含更短的连接，那么卷积网络的训练可以更深入、更准确、更有效。在本文中，我们采纳了这一研究结果，并提出了密集卷积网络（DenseNet），它以前馈的方式将每一层连接到每一层。传统的L层卷积网络有L个连接——每层与其下一层之间有一个连接，而我们的网络有L(L+1)/2个直接连接。对于每一层，前面所有层的特征映射被用作输入，而它自己的特征映射被用作到所有后续层的输入。DenseNet有几个显著的优点：它们缓解了消失梯度问题，加强了特征传播，鼓励了特征重用，并大大减少了参数数量。我们在四个竞争激烈的目标识别基准任务（CIFAR-10、CIFAR-100、SVHN和ImageNet）上对我们提出的体系结构进行了评估。DenseNet在大多数方面都比最先进的技术有了很大的改进，同时需要更少的计算来实现高性能。代码和预训练模型可在<a href=\"https://github.com/liuzhuang13/DenseNet\">此处</a>找到。</p>\n<p><strong>参考</strong><br>[1] <em>Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.</em><a href=\"https://arxiv.org/abs/1608.06993\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>DenseNet_PyTorch</em><a href=\"https://github.com/liuzhuang13/DenseNet\">[GitHub]</a><br>[2] <em>DenseNet_TensorFlow</em><a href=\"https://github.com/flyyufelix/DenseNet-Keras\">[GitHub]</a><br>[3] <em>DenseNet_MXNet</em><a href=\"https://github.com/miraclewkf/DenseNet\">[GitHub]</a><br>[4] <em>DenseNet_Caffe</em><a href=\"https://github.com/shicai/DenseNet-Caffe\">[GitHub]</a></p>\n","more":"<p><strong>摘要</strong><br>最近的研究表明，如果卷积网络在靠近输入的层和靠近输出的层之间包含更短的连接，那么卷积网络的训练可以更深入、更准确、更有效。在本文中，我们采纳了这一研究结果，并提出了密集卷积网络（DenseNet），它以前馈的方式将每一层连接到每一层。传统的L层卷积网络有L个连接——每层与其下一层之间有一个连接，而我们的网络有L(L+1)/2个直接连接。对于每一层，前面所有层的特征映射被用作输入，而它自己的特征映射被用作到所有后续层的输入。DenseNet有几个显著的优点：它们缓解了消失梯度问题，加强了特征传播，鼓励了特征重用，并大大减少了参数数量。我们在四个竞争激烈的目标识别基准任务（CIFAR-10、CIFAR-100、SVHN和ImageNet）上对我们提出的体系结构进行了评估。DenseNet在大多数方面都比最先进的技术有了很大的改进，同时需要更少的计算来实现高性能。代码和预训练模型可在<a href=\"https://github.com/liuzhuang13/DenseNet\">此处</a>找到。</p>\n<p><strong>参考</strong><br>[1] <em>Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.</em><a href=\"https://arxiv.org/abs/1608.06993\">[pdf]</a></p>\n<p><strong>源码</strong><br>[1] <em>DenseNet_PyTorch</em><a href=\"https://github.com/liuzhuang13/DenseNet\">[GitHub]</a><br>[2] <em>DenseNet_TensorFlow</em><a href=\"https://github.com/flyyufelix/DenseNet-Keras\">[GitHub]</a><br>[3] <em>DenseNet_MXNet</em><a href=\"https://github.com/miraclewkf/DenseNet\">[GitHub]</a><br>[4] <em>DenseNet_Caffe</em><a href=\"https://github.com/shicai/DenseNet-Caffe\">[GitHub]</a></p>\n","categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"目标检测","path":"api/tags/目标检测.json"},{"name":"DenseNet","path":"api/tags/DenseNet.json"}]}