{"total":112,"pageSize":10,"pageCount":12,"data":[{"title":"谷歌_Interspeech2017_Recurrent Neural Aligner：An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping","slug":"Paper034","date":"2021-02-21T09:20:55.000Z","updated":"2021-02-21T09:24:46.000Z","comments":true,"path":"api/articles/Paper034.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_034-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"},{"name":"RNA","path":"api/tags/RNA.json"}]},{"title":"多伦多大学_ICML2012_Sequence Transduction with Recurrent Neural Networks","slug":"Paper033","date":"2021-02-21T08:50:48.000Z","updated":"2021-02-21T09:07:23.000Z","comments":true,"path":"api/articles/Paper033.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_033-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"RNN-T","path":"api/tags/RNN-T.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"}]},{"title":"多伦多大学_ICML2006_Connectionist temporal classification：labelling unsegmented sequence data with recurrent neural networks","slug":"Paper032","date":"2021-02-19T14:33:33.000Z","updated":"2021-02-19T15:16:42.000Z","comments":true,"path":"api/articles/Paper032.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_032-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"}]},{"title":"CMU_ICASSP2016_Listen, Attend and Spell","slug":"Paper031","date":"2021-02-19T08:44:24.000Z","updated":"2021-02-19T09:31:22.000Z","comments":true,"path":"api/articles/Paper031.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_031-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"BLSTM","path":"api/tags/BLSTM.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"},{"name":"LAS","path":"api/tags/LAS.json"}]},{"title":"华盛顿州立大学_ICASSP2018_Attention-Based Models for Text-Dependent Speaker Verification","slug":"Paper030","date":"2021-02-14T09:35:26.000Z","updated":"2021-02-14T09:49:10.000Z","comments":true,"path":"api/articles/Paper030.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_030-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"说话人认证","path":"api/tags/说话人认证.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"LSTM","path":"api/tags/LSTM.json"},{"name":"TE2E","path":"api/tags/TE2E.json"}]},{"title":"DFKI_ICASSP2016_End-to-End Text-Dependent Speaker Verification","slug":"Paper029","date":"2021-02-14T04:38:27.000Z","updated":"2021-02-14T05:22:07.000Z","comments":true,"path":"api/articles/Paper029.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_029-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"说话人认证","path":"api/tags/说话人认证.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"LSTM","path":"api/tags/LSTM.json"},{"name":"TE2E","path":"api/tags/TE2E.json"}]},{"title":"深度学习与人类语言处理课程_李宏毅_国立台湾大学","slug":"Tutorial002","date":"2021-02-08T01:55:35.000Z","updated":"2021-02-26T04:24:26.000Z","comments":true,"path":"api/articles/Tutorial002.json","excerpt":null,"keywords":null,"cover":"/img/tutorials/tutorial_002-01.jpg","content":null,"raw":null,"categories":[{"name":"Tutorial","path":"api/categories/Tutorial.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语音转换","path":"api/tags/语音转换.json"},{"name":"说话人认证","path":"api/tags/说话人认证.json"},{"name":"深度学习","path":"api/tags/深度学习.json"},{"name":"语音分离","path":"api/tags/语音分离.json"}]},{"title":"谷歌_Interspeech2020_Conformer：Convolution-augmented Transformer for Speech Recognition","slug":"Paper028","date":"2021-02-02T02:04:40.000Z","updated":"2021-02-02T02:14:18.000Z","comments":true,"path":"api/articles/Paper028.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_028-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"CNN","path":"api/tags/CNN.json"},{"name":"Transformer","path":"api/tags/Transformer.json"},{"name":"Conformer","path":"api/tags/Conformer.json"}]},{"title":"SLT2021-儿童语音识别挑战赛研讨会","slug":"Tutorial001","date":"2021-02-01T06:47:57.000Z","updated":"2021-02-08T11:20:58.000Z","comments":true,"path":"api/articles/Tutorial001.json","excerpt":null,"keywords":null,"cover":"/img/tutorials/tutorial_001-01.jpg","content":null,"raw":null,"categories":[{"name":"Tutorial","path":"api/categories/Tutorial.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"}]},{"title":"谷歌_ICASSP2018_Generalized End-to-End Loss for Speaker Verification","slug":"Paper027","date":"2021-01-27T15:02:39.000Z","updated":"2021-01-27T15:11:39.000Z","comments":true,"path":"api/articles/Paper027.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_027-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"说话人认证","path":"api/tags/说话人认证.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"LSTM","path":"api/tags/LSTM.json"},{"name":"GE2E","path":"api/tags/GE2E.json"},{"name":"TE2E","path":"api/tags/TE2E.json"}]}]}