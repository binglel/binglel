{"name":"CTC","postlist":[{"title":"约翰斯·霍普金斯大学_Interspeech2018_ESPnet：End-to-End Speech Processing Toolkit","slug":"Paper013","date":"2021-01-07T01:28:32.000Z","updated":"2021-01-07T02:09:33.000Z","comments":true,"path":"api/articles/Paper013.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_013-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语言模型","path":"api/tags/语言模型.json"},{"name":"HMM","path":"api/tags/HMM.json"},{"name":"Kaldi","path":"api/tags/Kaldi.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"DNN","path":"api/tags/DNN.json"},{"name":"TDNN","path":"api/tags/TDNN.json"},{"name":"BLSTM","path":"api/tags/BLSTM.json"},{"name":"LF-MMI","path":"api/tags/LF-MMI.json"},{"name":"Chain","path":"api/tags/Chain.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"RNNLM","path":"api/tags/RNNLM.json"}]},{"title":"MERL_ICASSP2017_Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning","slug":"Paper014","date":"2021-01-09T09:45:40.000Z","updated":"2021-03-23T09:43:54.000Z","comments":true,"path":"api/articles/Paper014.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_014-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"RNN","path":"api/tags/RNN.json"}]},{"title":"MERL_2017_Hybrid CTC/Attention Architecture for End-to-End Speech Recognition","slug":"Paper015","date":"2021-01-10T15:17:45.000Z","updated":"2021-01-11T15:10:42.000Z","comments":true,"path":"api/articles/Paper015.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_015-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"RNN","path":"api/tags/RNN.json"}]},{"title":"百度_20141219_Deep Speech：Scaling up end-to-end speech recognition","slug":"Paper016","date":"2021-01-11T14:45:26.000Z","updated":"2021-01-11T14:53:54.000Z","comments":true,"path":"api/articles/Paper016.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_016-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语言模型","path":"api/tags/语言模型.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"N-Gram","path":"api/tags/N-Gram.json"}]},{"title":"百度_ICML2015_Deep Speech 2：End-to-End Speech Recognition in English and Mandarin","slug":"Paper019","date":"2021-01-18T14:39:52.000Z","updated":"2021-03-20T08:14:55.000Z","comments":true,"path":"api/articles/Paper019.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_019-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语言模型","path":"api/tags/语言模型.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"CNN","path":"api/tags/CNN.json"},{"name":"GRU","path":"api/tags/GRU.json"},{"name":"LSTM","path":"api/tags/LSTM.json"},{"name":"KenLM","path":"api/tags/KenLM.json"}]},{"title":"百度_ASRU2017_Exploring Neural Transducers for End-to-End Speech Recognition","slug":"Paper020","date":"2021-01-19T14:30:36.000Z","updated":"2021-01-19T15:03:41.000Z","comments":true,"path":"api/articles/Paper020.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_020-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"RNN-T","path":"api/tags/RNN-T.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"}]},{"title":"出门问问_20201210_Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition","slug":"Paper023","date":"2021-01-23T10:26:31.000Z","updated":"2021-03-31T06:19:54.000Z","comments":true,"path":"api/articles/Paper023.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_023-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"Attention","path":"api/tags/Attention.json"}]},{"title":"出门问问_ICASSP2019_End-To-End Speech Recognition Using A High Rank LSTM-CTC Based Model","slug":"Paper024","date":"2021-01-24T02:46:46.000Z","updated":"2021-03-31T06:18:50.000Z","comments":true,"path":"api/articles/Paper024.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_024-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"LSTM","path":"api/tags/LSTM.json"}]},{"title":"多伦多大学_ICML2006_Connectionist temporal classification：labelling unsegmented sequence data with recurrent neural networks","slug":"Paper032","date":"2021-02-19T14:33:33.000Z","updated":"2021-02-19T15:16:42.000Z","comments":true,"path":"api/articles/Paper032.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_032-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"}]}]}