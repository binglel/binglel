{"name":"Griffin-Lim","postlist":[{"title":"谷歌_Interspeech2017_Tacotron：Towards End-to-End Speech Synthesis","slug":"Paper001","date":"2020-12-23T12:46:14.000Z","updated":"2021-03-29T07:35:19.000Z","comments":true,"path":"api/articles/Paper001.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_001-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"合成器","path":"api/tags/合成器.json"},{"name":"Tacotron","path":"api/tags/Tacotron.json"},{"name":"声码器","path":"api/tags/声码器.json"},{"name":"Griffin-Lim","path":"api/tags/Griffin-Lim.json"}]},{"title":"斯坦福大学_2018_Storytime - End to end neural networks for audiobooks","slug":"Paper006","date":"2020-12-27T13:25:08.000Z","updated":"2021-01-07T02:21:59.000Z","comments":true,"path":"api/articles/Paper006.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_006-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"合成器","path":"api/tags/合成器.json"},{"name":"Tacotron","path":"api/tags/Tacotron.json"},{"name":"声码器","path":"api/tags/声码器.json"},{"name":"Griffin-Lim","path":"api/tags/Griffin-Lim.json"}]},{"title":"谷歌_ICML2018_Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron","slug":"Paper007","date":"2020-12-28T13:56:52.000Z","updated":"2020-12-28T14:12:40.000Z","comments":true,"path":"api/articles/Paper007.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_007-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"语音转换","path":"api/tags/语音转换.json"},{"name":"说话人风格迁移","path":"api/tags/说话人风格迁移.json"},{"name":"合成器","path":"api/tags/合成器.json"},{"name":"Tacotron","path":"api/tags/Tacotron.json"},{"name":"声码器","path":"api/tags/声码器.json"},{"name":"Griffin-Lim","path":"api/tags/Griffin-Lim.json"},{"name":"WaveNet","path":"api/tags/WaveNet.json"},{"name":"韵律编码器","path":"api/tags/韵律编码器.json"}]},{"title":"谷歌_20180323_Style Tokens：Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis","slug":"Paper008","date":"2020-12-28T14:12:56.000Z","updated":"2020-12-28T14:25:54.000Z","comments":true,"path":"api/articles/Paper008.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_008-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"语音转换","path":"api/tags/语音转换.json"},{"name":"说话人风格迁移","path":"api/tags/说话人风格迁移.json"},{"name":"合成器","path":"api/tags/合成器.json"},{"name":"Tacotron","path":"api/tags/Tacotron.json"},{"name":"声码器","path":"api/tags/声码器.json"},{"name":"Griffin-Lim","path":"api/tags/Griffin-Lim.json"},{"name":"WaveNet","path":"api/tags/WaveNet.json"},{"name":"声纹编码器","path":"api/tags/声纹编码器.json"},{"name":"韵律编码器","path":"api/tags/韵律编码器.json"}]},{"title":"台湾大学_Interspeech2019_One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization","slug":"Paper010","date":"2020-12-28T14:56:11.000Z","updated":"2021-05-27T03:25:24.000Z","comments":true,"path":"api/articles/Paper010.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_010-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音合成","path":"api/tags/语音合成.json"},{"name":"语音转换","path":"api/tags/语音转换.json"},{"name":"合成器","path":"api/tags/合成器.json"},{"name":"Tacotron","path":"api/tags/Tacotron.json"},{"name":"声码器","path":"api/tags/声码器.json"},{"name":"Griffin-Lim","path":"api/tags/Griffin-Lim.json"},{"name":"声纹编码器","path":"api/tags/声纹编码器.json"},{"name":"内容编码器","path":"api/tags/内容编码器.json"},{"name":"Instance Normalization","path":"api/tags/Instance Normalization.json"}]}]}