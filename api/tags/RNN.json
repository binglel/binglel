{"name":"RNN","postlist":[{"title":"MERL_ICASSP2017_Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning","slug":"Paper014","date":"2021-01-09T09:45:40.000Z","updated":"2021-03-23T09:43:54.000Z","comments":true,"path":"api/articles/Paper014.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_014-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"RNN","path":"api/tags/RNN.json"}]},{"title":"MERL_2017_Hybrid CTC/Attention Architecture for End-to-End Speech Recognition","slug":"Paper015","date":"2021-01-10T15:17:45.000Z","updated":"2021-01-11T15:10:42.000Z","comments":true,"path":"api/articles/Paper015.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_015-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"Attention","path":"api/tags/Attention.json"},{"name":"RNN","path":"api/tags/RNN.json"}]},{"title":"百度_20141219_Deep Speech：Scaling up end-to-end speech recognition","slug":"Paper016","date":"2021-01-11T14:45:26.000Z","updated":"2021-01-11T14:53:54.000Z","comments":true,"path":"api/articles/Paper016.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_016-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语言模型","path":"api/tags/语言模型.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"N-Gram","path":"api/tags/N-Gram.json"}]},{"title":"百度_ICML2015_Deep Speech 2：End-to-End Speech Recognition in English and Mandarin","slug":"Paper019","date":"2021-01-18T14:39:52.000Z","updated":"2021-03-20T08:14:55.000Z","comments":true,"path":"api/articles/Paper019.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_019-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"语言模型","path":"api/tags/语言模型.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"声学模型","path":"api/tags/声学模型.json"},{"name":"解码器","path":"api/tags/解码器.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"CNN","path":"api/tags/CNN.json"},{"name":"GRU","path":"api/tags/GRU.json"},{"name":"LSTM","path":"api/tags/LSTM.json"},{"name":"KenLM","path":"api/tags/KenLM.json"}]},{"title":"多伦多大学_ICML2006_Connectionist temporal classification：labelling unsegmented sequence data with recurrent neural networks","slug":"Paper032","date":"2021-02-19T14:33:33.000Z","updated":"2021-02-19T15:16:42.000Z","comments":true,"path":"api/articles/Paper032.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_032-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"End-to-End","path":"api/tags/End-to-End.json"},{"name":"CTC","path":"api/tags/CTC.json"},{"name":"RNN","path":"api/tags/RNN.json"}]},{"title":"多伦多大学_ICML2012_Sequence Transduction with Recurrent Neural Networks","slug":"Paper033","date":"2021-02-21T08:50:48.000Z","updated":"2021-02-21T09:07:23.000Z","comments":true,"path":"api/articles/Paper033.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_033-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"RNN-T","path":"api/tags/RNN-T.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"}]},{"title":"谷歌_Interspeech2017_Recurrent Neural Aligner：An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping","slug":"Paper034","date":"2021-02-21T09:20:55.000Z","updated":"2021-02-21T09:24:46.000Z","comments":true,"path":"api/articles/Paper034.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_034-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"},{"name":"RNA","path":"api/tags/RNA.json"}]},{"title":"谷歌_20160804_A Neural Transducer","slug":"Paper035","date":"2021-02-21T09:28:16.000Z","updated":"2021-02-21T09:44:48.000Z","comments":true,"path":"api/articles/Paper035.json","excerpt":null,"keywords":null,"cover":"/img/papers/paper_035-01.jpg","content":null,"raw":null,"categories":[{"name":"Paper","path":"api/categories/Paper.json"}],"tags":[{"name":"语音识别","path":"api/tags/语音识别.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"RNN-T","path":"api/tags/RNN-T.json"},{"name":"Sequence-to-Sequence","path":"api/tags/Sequence-to-Sequence.json"}]},{"title":"神经网络与深度学习_邱锡鹏_复旦大学","slug":"Tutorial005","date":"2021-02-26T04:24:56.000Z","updated":"2021-02-26T04:42:14.000Z","comments":true,"path":"api/articles/Tutorial005.json","excerpt":null,"keywords":null,"cover":"/img/tutorials/tutorial_005-01.jpg","content":null,"raw":null,"categories":[{"name":"Tutorial","path":"api/categories/Tutorial.json"}],"tags":[{"name":"Attention","path":"api/tags/Attention.json"},{"name":"RNN","path":"api/tags/RNN.json"},{"name":"CNN","path":"api/tags/CNN.json"},{"name":"深度学习","path":"api/tags/深度学习.json"}]}]}